<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decision Tree Classifier - Dr. Baker Marketing Analytics</title>
    <link rel="stylesheet" href="../../../shared/css/main.css">
    <link rel="stylesheet" href="../../../shared/css/auth_bar.css">
    <link rel="stylesheet" href="styles.css">
    <script src="../../../shared/js/tracking.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-290ZJ9RE04"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-290ZJ9RE04');
    </script>
</head>
<body>
    <!-- Auth Bar -->
    <div class="auth-bar">
        <div class="auth-bar__container">
            <div></div>
            <div id="auth-bar-content" class="auth-bar__links">
                <a href="../../../admin_pages/login.html">Login</a>
                <a href="../../../admin_pages/register.html">Create Account</a>
            </div>
        </div>
    </div>

    <header class="intro hero-header">
        <div class="hero-header__top">
            <h1>üå≥ Decision Tree Classifier</h1>
            <div class="hero-context">
                <span class="badge">Machine Learning</span>
            </div>
        </div>
        <p class="hero-header__lede">
            Build and interpret classification trees for marketing decisions. Understand how decision trees segment customers
            by learning splitting rules from data. Toggle between automated building and manual exploration to develop intuition
            for how trees partition feature space.
        </p>
    </header>

    <!-- Professor Mode Banner -->
    <div class="professor-mode-banner">
        <div class="professor-mode-content">
            <div class="professor-mode-info">
                <h3>üë®‚Äçüè´ Professor Mode: Guided Learning Experience</h3>
                <p>New to decision trees? Enable Professor Mode for step-by-step guidance through building and interpreting your first tree!</p>
            </div>
            <label class="professor-mode-toggle">
                <input type="checkbox" id="professorMode">
                <span>Enable Professor Mode</span>
            </label>
        </div>
    </div>

    <!-- Overview Section -->
    <section class="test-overview" id="overview-section" aria-labelledby="test-overview-heading">
        <!-- Tutorial target: tut-overview-section -->
        <div id="tut-overview-section">
        <div class="overview-container">
            <h2 id="test-overview-heading">OVERVIEW & OBJECTIVE</h2>
            <div class="card">
                <p>
                    A <strong>decision tree classifier</strong> is a supervised machine learning algorithm that learns to predict categorical 
                    outcomes by finding the best sequence of yes/no questions to ask about your data. Each question creates a "split" 
                    that separates customers into increasingly homogeneous groups.
                </p>
                <p class="method-description">
                    <strong>The CART Algorithm:</strong> This tool uses Classification and Regression Trees (CART), which builds 
                    binary trees by finding the split that maximizes <em>impurity reduction</em> at each node. The algorithm 
                    evaluates every possible split point for every variable and chooses the one that best separates the classes.
                </p>
                <details class="intro-notes">
                    <summary>Key Concepts & When to Use</summary>
                    <div class="notes-content">
                        <div class="concept-grid">
                            <div class="concept-item">
                                <h4>üìä Best For</h4>
                                <ul>
                                    <li>Customer segmentation with clear decision rules</li>
                                    <li>Churn prediction with actionable thresholds</li>
                                    <li>Lead scoring and qualification</li>
                                    <li>Campaign targeting with explainable criteria</li>
                                </ul>
                            </div>
                            <div class="concept-item">
                                <h4>‚ö†Ô∏è Limitations</h4>
                                <ul>
                                    <li>Can overfit with deep trees or small data</li>
                                    <li>Axis-parallel splits only (can't capture diagonal boundaries)</li>
                                    <li>Sensitive to small data changes (high variance)</li>
                                    <li>May miss complex interactions without sufficient depth</li>
                                </ul>
                            </div>
                            <div class="concept-item">
                                <h4>üéØ Output</h4>
                                <ul>
                                    <li>IF-THEN rules directly usable in campaigns</li>
                                    <li>Feature importance rankings</li>
                                    <li>Probability estimates per segment</li>
                                    <li>Visual tree structure for stakeholder communication</li>
                                </ul>
                            </div>
                            <div class="concept-item">
                                <h4>üìà Marketing Advantage</h4>
                                <p>Unlike "black box" models, decision trees produce <strong>interpretable rules</strong> you can explain 
                                to stakeholders and directly translate into marketing automation logic.</p>
                            </div>
                        </div>
                    </div>
                </details>
            </div>
        </div>
        </div><!-- /tut-overview-section -->
    </section>

    <main class="app-main">
        <!-- Step 1: Choose Scenario -->
        <section class="step-card" id="step1">
            <!-- Tutorial target: tut-step1-section -->
            <div id="tut-step1-section">
            <div class="step-header">
                <h2>üìä Step 1: Choose Your Business Problem</h2>
            </div>
            
            <div class="card">
                <div class="scenario-controls">
                    <label for="scenario-select">Load a marketing scenario:</label>
                    <div class="scenario-controls__input">
                        <select id="scenario-select">
                            <option value="">-- Select a scenario --</option>
                        </select>
                        <button id="scenario-download" class="secondary" type="button" disabled>
                            Download scenario dataset
                        </button>
                    </div>
                </div>
                
                <div id="scenario-description" class="scenario-description-container">
                    <p class="scenario-placeholder">
                        Select a scenario above to see the business context and variables, or upload your own dataset below.
                    </p>
                </div>

                <!-- Custom Upload -->
                <div class="upload-section">
                    <h4>Or Upload Your Own Data</h4>
                    <div class="dropzone" id="data-dropzone">
                        <p class="dropzone-title">Drag & Drop CSV file</p>
                        <p class="dropzone-note">Include headers. One categorical outcome column + predictor columns (numeric or categorical).</p>
                        <button type="button" id="browse-btn" class="btn secondary">Browse files</button>
                    </div>
                    <input type="file" id="file-input" accept=".csv,.tsv,.txt" hidden>
                    <div class="upload-footer">
                        <p class="upload-status" id="upload-status">No file uploaded.</p>
                        <button type="button" id="template-download" class="btn-link">
                            üì• Download sample template
                        </button>
                    </div>
                    
                    <!-- Variable Assignment (shown after upload) -->
                    <div id="variable-assignment" class="variable-assignment hidden">
                        <h4>Assign Variables</h4>
                        <div class="variable-row">
                            <label for="outcome-select">Outcome Variable (what to predict):</label>
                            <select id="outcome-select"></select>
                        </div>
                        <div id="predictor-list" class="predictor-list">
                            <!-- Predictors will be listed here with clickable type toggles -->
                        </div>
                        <p class="predictor-hint">üí° Click a predictor chip to toggle between categorical and continuous.</p>
                    </div>
                </div>
            </div>
        </div><!-- /tut-step1-section -->
        </section>

        <!-- Step 2: Build Settings -->
        <section class="step-card" id="step2">
            <!-- Tutorial target: tut-step2-section -->
            <div id="tut-step2-section">
            <div class="step-header">
                <h2>‚öôÔ∏è Step 2: Configure Tree Settings & Model</h2>
            </div>
            
            <div class="card">
                <div class="settings-grid">
                    <!-- Build Mode Toggle -->
                    <div class="setting-group mode-toggle-group">
                        <label>Build Mode</label>
                        <div class="mode-toggle">
                            <button type="button" id="mode-auto" class="mode-btn active">ü§ñ Auto</button>
                            <button type="button" id="mode-manual" class="mode-btn">üõ†Ô∏è Manual</button>
                        </div>
                        <p class="setting-help" id="mode-help">
                            Algorithm finds optimal splits automatically.
                        </p>
                    </div>

                    <!-- Tree Constraints -->
                    <div class="setting-group">
                        <label for="max-depth">Max Depth: <span id="max-depth-val">3</span></label>
                        <input type="range" id="max-depth" min="1" max="6" value="3" step="1">
                        <p class="setting-help">Maximum levels from root to deepest leaf.</p>
                    </div>

                    <div class="setting-group">
                        <label for="min-samples-leaf">Min Samples per Leaf: <span id="min-samples-val">10</span></label>
                        <input type="range" id="min-samples-leaf" min="1" max="50" value="10" step="1">
                        <p class="setting-help">Prevents tiny, overfit leaf nodes.</p>
                    </div>

                    <!-- Target Class Selector -->
                    <div class="setting-group target-class-group">
                        <label for="target-class-select">Target Class (Positive Outcome)</label>
                        <select id="target-class-select" disabled>
                            <option value="">-- Load data first --</option>
                        </select>
                        <p class="setting-help">Which outcome class should be treated as "success" for metrics like precision, recall, and ROC curves.</p>
                    </div>
                </div>

                <!-- Advanced Settings (Collapsible) -->
                <details class="advanced-settings">
                    <summary>‚öôÔ∏è Advanced Settings</summary>
                    <div class="advanced-settings-content">
                        <div class="settings-grid">
                            <div class="setting-group">
                                <label for="split-criterion">Split Criterion</label>
                                <select id="split-criterion">
                                    <option value="gini" selected>Gini Impurity</option>
                                    <option value="entropy">Information Gain (Entropy)</option>
                                </select>
                                <p class="setting-help">How to measure quality of splits.</p>
                            </div>

                            <div class="setting-group">
                                <label for="train-split">Train/Test Split: <span id="train-split-val">70</span>%</label>
                                <input type="range" id="train-split" min="50" max="90" value="70" step="5">
                                <p class="setting-help">Percentage of data for training vs testing.</p>
                            </div>

                            <div class="setting-group">
                                <label for="random-seed">Random Seed (for Reproducibility)</label>
                                <div class="seed-input-group">
                                    <input type="text" id="random-seed" placeholder="Auto-generated">
                                    <button type="button" id="new-seed-btn" class="btn-small" title="Generate new random seed">üé≤</button>
                                </div>
                                <p class="setting-help">Set a number (e.g. "12345") to get the same train/test split each time. Useful for classroom demos.</p>
                            </div>
                        </div>
                    </div>
                </details>

                <!-- Interpretation Aid for Settings -->
                <details class="interpretation-aid">
                    <summary>üìö Understanding Tree Settings</summary>
                    <div class="interpretation-content">
                        <div class="guide-section">
                            <h5>ü§ñ Auto vs üõ†Ô∏è Manual Mode</h5>
                            <p><strong>Auto mode</strong> uses the CART algorithm to find the statistically "best" split at each node‚Äîthe one that most reduces impurity (Gini or Entropy). This is efficient and finds patterns humans might miss.</p>
                            <p><strong>Manual mode</strong> is primarily an <em>educational tool</em> to help you develop intuition for how decision trees partition data. You choose splits based on your own logic, which helps you understand the tradeoffs involved.</p>
                            <div class="educational-note">
                                <p><strong>üìö Real-World Practice:</strong> In industry, decision trees are virtually always built automatically using impurity-based criteria (Gini or Information Gain) combined with <strong>hyperparameter tuning</strong>‚Äîsystematically testing different values of max depth, min samples per leaf, etc., to find the best-performing configuration. Manual tree construction is useful for learning but impractical at scale.</p>
                                <p>That said, manual mode can occasionally be valuable for creating <strong>rule-based segments</strong> where business logic matters more than pure predictive accuracy‚Äîe.g., when stakeholders need round-number thresholds that are easy to communicate and implement.</p>
                            </div>
                        </div>
                        <div class="guide-section">
                            <h5>üå≤ Max Depth</h5>
                            <p>Depth controls complexity. A depth-1 tree (a "stump") makes one split. Depth-3 creates up to 8 segments. Deeper trees capture more patterns but risk <strong>overfitting</strong>‚Äîmemorizing training data quirks that don't generalize.</p>
                            <p><em>Marketing rule of thumb:</em> Start with depth 3-4. If test accuracy drops significantly from training accuracy, the tree is overfitting‚Äîreduce depth.</p>
                        </div>
                        <div class="guide-section">
                            <h5>üéØ Target Class</h5>
                            <p>For binary classification, metrics like precision and recall are calculated relative to one "positive" class. In marketing:</p>
                            <ul>
                                <li><strong>Churn prediction:</strong> "Churned" is typically the target (we want to catch churners)</li>
                                <li><strong>Conversion:</strong> "Converted" is the target</li>
                                <li><strong>Lead scoring:</strong> "Qualified" or "Won" is usually the target</li>
                            </ul>
                        </div>
                        <div class="guide-section">
                            <h5>‚öñÔ∏è Gini vs Entropy (Split Criteria)</h5>
                            <p>Both are <strong>impurity measures</strong> that quantify how mixed the classes are at a node. The algorithm evaluates every possible split and chooses the one that maximizes impurity reduction.</p>
                            <ul>
                                <li><strong>Gini Impurity:</strong> Measures the probability of misclassifying a randomly chosen element. Formula: 1 - Œ£(p<sub>i</sub>¬≤). Computationally faster, tends to favor larger partitions.</li>
                                <li><strong>Entropy (Information Gain):</strong> From information theory‚Äîmeasures the expected "surprise" or uncertainty. Formula: -Œ£(p<sub>i</sub> √ó log‚ÇÇ(p<sub>i</sub>)). Can find slightly more balanced splits.</li>
                            </ul>
                            <p>In practice, they usually produce nearly identical trees. Gini is the default in most implementations (including scikit-learn) due to speed.</p>
                        </div>
                    </div>
                </details>
            </div>
        </div><!-- /tut-step2-section -->
        </section>

        <!-- Step 3: Build the Tree -->
        <section class="step-card" id="step3">
            <!-- Tutorial target: tut-step3-section -->
            <div id="tut-step3-section">
            <div class="step-header">
                <h2>üå≥ Step 3: Build the Tree</h2>
                <div class="control-buttons">
                    <button type="button" id="build-btn" class="btn-primary" disabled>Build Tree</button>
                    <button type="button" id="finish-building-btn" class="btn-success hidden">‚úì Finish Building</button>
                    <button type="button" id="reset-btn" class="btn-secondary" disabled>Reset</button>
                </div>
            </div>
            
            <div class="card">
                <!-- Manual mode instructions -->
                <div id="manual-mode-instructions" class="manual-instructions hidden">
                    <p>üëÜ <strong>Click on any node</strong> marked "Click to split" to choose how to split it, or click <strong>"Finish Building"</strong> when done.</p>
                </div>
                
                <!-- Tree Visualization Container -->
                <!-- Tutorial target: tut-tree-container -->
                <div id="tree-container" class="tree-container tut-tree-container">
                    <div class="tree-placeholder">
                        <p>üå± Select a scenario and click "Build Tree" to grow your decision tree.</p>
                    </div>
                </div>
                <p class="tree-nav-hint">üí° <strong>Tip:</strong> Use scroll wheel to zoom, click &amp; drag to pan. Click any node to see detailed statistics.</p>

                <!-- Expanded Node Editor (appears when node is clicked in manual mode) -->
                <div id="node-editor" class="node-editor hidden">
                    <div class="node-editor-header">
                        <h4>üìä Customize Split</h4>
                        <button type="button" id="close-editor" class="close-btn">‚úï</button>
                    </div>
                    <div id="node-editor-content" class="node-editor-content">
                        <!-- Dynamic content based on feature type -->
                    </div>
                    <div class="node-editor-actions">
                        <button type="button" id="apply-split-btn" class="btn-primary">Apply Split</button>
                        <button type="button" id="make-leaf-btn" class="btn-secondary">Make Leaf Instead</button>
                        <button type="button" id="cancel-split-btn" class="btn-ghost">Cancel</button>
                    </div>
                </div>
            </div>
        </div><!-- /tut-step3-section -->
        </section>

        <!-- Step 4: Model Evaluation -->
        <section class="step-card" id="step4">
            <div class="step-header">
                <h2>üìà Step 4: Model Evaluation</h2>
            </div>
            
            <div class="card">
                <!-- Summary Metrics -->
                <!-- Tutorial target: tut-metrics-section -->
                <div class="metrics-summary" id="tut-metrics-section">
                    <div class="metric-card">
                        <span class="metric-label">Test Accuracy</span>
                        <span class="metric-value" id="metric-accuracy">--</span>
                    </div>
                    <div class="metric-card">
                        <span class="metric-label">Train Accuracy</span>
                        <span class="metric-value" id="metric-train-accuracy">--</span>
                    </div>
                    <div class="metric-card">
                        <span class="metric-label">Precision</span>
                        <span class="metric-value" id="metric-precision">--</span>
                    </div>
                    <div class="metric-card">
                        <span class="metric-label">Recall</span>
                        <span class="metric-value" id="metric-recall">--</span>
                    </div>
                    <div class="metric-card">
                        <span class="metric-label">F1 Score</span>
                        <span class="metric-value" id="metric-f1">--</span>
                    </div>
                </div>

                <!-- Metrics Interpretation Aid -->
                <details class="interpretation-aid metrics-explainer">
                    <summary>üìö Understanding Classification Metrics</summary>
                    <div class="interpretation-content">
                        <div class="metrics-explainer-grid">
                            <div class="guide-section">
                                <h5>üéØ Accuracy</h5>
                                <p class="formula">= (Correct Predictions) / (Total Predictions)</p>
                                <p><strong>What it measures:</strong> Overall correctness‚Äîhow often the model gets it right across all classes.</p>
                                <p><strong>Marketing context:</strong> "Out of all customers we scored, what percentage did we classify correctly?"</p>
                                <p class="caution">‚ö†Ô∏è <strong>Caution:</strong> Accuracy can be misleading with imbalanced classes. If only 5% of customers churn, predicting "no churn" for everyone gives 95% accuracy but catches zero churners!</p>
                            </div>
                            <div class="guide-section">
                                <h5>üîç Precision</h5>
                                <p class="formula">= True Positives / (True Positives + False Positives)</p>
                                <p><strong>What it measures:</strong> When you predict the target class, how often are you right?</p>
                                <p><strong>Marketing context:</strong> "Of the customers we flagged as likely churners, what percentage actually churned?"</p>
                                <p><strong>When to prioritize:</strong> When false positives are costly. Example: Sending expensive retention offers to customers who weren't going to churn anyway wastes budget.</p>
                            </div>
                            <div class="guide-section">
                                <h5>üì° Recall (Sensitivity)</h5>
                                <p class="formula">= True Positives / (True Positives + False Negatives)</p>
                                <p><strong>What it measures:</strong> Of all actual positive cases, how many did you catch?</p>
                                <p><strong>Marketing context:</strong> "Of all customers who actually churned, what percentage did we identify in advance?"</p>
                                <p><strong>When to prioritize:</strong> When missing positives is costly. Example: Missing a high-value customer about to churn means losing that revenue forever.</p>
                            </div>
                            <div class="guide-section">
                                <h5>‚öñÔ∏è F1 Score</h5>
                                <p class="formula">= 2 √ó (Precision √ó Recall) / (Precision + Recall)</p>
                                <p><strong>What it measures:</strong> Harmonic mean of precision and recall‚Äîa single metric that balances both.</p>
                                <p><strong>Marketing context:</strong> "Overall, how well are we balancing catching churners vs. not wasting resources on false alarms?"</p>
                                <p><strong>When to use:</strong> When you need a single number to compare models and care about both precision and recall. The harmonic mean penalizes extreme imbalances.</p>
                            </div>
                        </div>
                        <div class="guide-section full-width">
                            <h5>ü§î The Precision-Recall Tradeoff</h5>
                            <p>You rarely maximize both. Being more aggressive (predicting "churn" more often) catches more actual churners (<strong>‚Üë recall</strong>) but includes more false alarms (<strong>‚Üì precision</strong>). Being conservative does the opposite.</p>
                            <p><strong>Business decision:</strong> What's the relative cost of missing a churner vs. wasting a retention offer on a loyal customer? That guides which metric to optimize.</p>
                        </div>
                    </div>
                </details>

                <!-- Detailed Evaluation Grid -->
                <div class="evaluation-grid">
                    <!-- Confusion Matrix -->
                    <!-- Tutorial target: tut-confusion-section -->
                    <div class="eval-panel" id="tut-confusion-section">
                        <h4>Confusion Matrix</h4>
                        <div id="confusion-matrix" class="confusion-matrix">
                            <p class="placeholder-text">Build a tree to see confusion matrix</p>
                        </div>
                        <details class="interpretation-aid compact">
                            <summary>How to read this</summary>
                            <div class="interpretation-content">
                                <p>Rows = <strong>Actual</strong> class, Columns = <strong>Predicted</strong> class.</p>
                                <ul>
                                    <li><strong>Diagonal (green):</strong> Correct predictions</li>
                                    <li><strong>Off-diagonal (red):</strong> Errors</li>
                                    <li><strong>False Positives:</strong> Predicted target, but wasn't (column sum minus diagonal)</li>
                                    <li><strong>False Negatives:</strong> Missed actual targets (row sum minus diagonal)</li>
                                </ul>
                                <p><em>Marketing tip:</em> Look at where errors concentrate. Confusing "Low Value" with "Medium Value" may be acceptable; confusing "Loyal" with "Churning" is not!</p>
                            </div>
                        </details>
                    </div>

                    <!-- ROC Curve (binary only) / Per-Class Metrics (multi-class) -->
                    <div class="eval-panel">
                        <h4 id="roc-panel-title">ROC Curve</h4>
                        <div id="roc-curve" class="roc-curve">
                            <p class="placeholder-text">Build a tree to see ROC curve</p>
                        </div>
                        <details class="interpretation-aid compact">
                            <summary>How to read this</summary>
                            <div class="interpretation-content">
                                <p><strong>ROC Curve</strong> (Receiver Operating Characteristic) plots True Positive Rate vs False Positive Rate at various thresholds.</p>
                                <ul>
                                    <li><strong>Diagonal line:</strong> Random guessing (AUC = 0.5)</li>
                                    <li><strong>Upper-left corner:</strong> Perfect classifier (AUC = 1.0)</li>
                                    <li><strong>AUC (Area Under Curve):</strong> Probability that a randomly chosen positive case ranks higher than a randomly chosen negative case</li>
                                </ul>
                                <p><strong>Interpretation guide:</strong></p>
                                <ul>
                                    <li>AUC 0.9-1.0: Excellent discrimination</li>
                                    <li>AUC 0.8-0.9: Good discrimination</li>
                                    <li>AUC 0.7-0.8: Fair discrimination</li>
                                    <li>AUC 0.6-0.7: Poor discrimination</li>
                                    <li>AUC 0.5-0.6: Barely better than random</li>
                                </ul>
                                <p><em>Marketing context:</em> High AUC means the model reliably ranks likely churners above non-churners, even if the exact threshold varies.</p>
                            </div>
                        </details>
                    </div>
                </div>

                <!-- Feature Importance -->
                <!-- Tutorial target: tut-importance-section -->
                <div class="eval-panel full-width" id="tut-importance-section">
                    <h4>Feature Importance</h4>
                    <div id="feature-importance" class="feature-importance">
                        <p class="placeholder-text">Build a tree to see feature importance</p>
                    </div>
                    <details class="interpretation-aid">
                        <summary>üìä How to Read Feature Importance (Important!)</summary>
                        <div class="interpretation-content">
                            <div class="guide-section">
                                <h5>What Feature Importance Tells You</h5>
                                <p><strong>Feature importance</strong> quantifies how much each predictor variable contributed to the tree's ability to separate classes. Think of it as answering: <em>"Which variables did the tree rely on most heavily when making decisions?"</em></p>
                                <p>Variables with <strong>high importance</strong> were used in splits that affected many observations and/or created big improvements in class purity. Variables with <strong>zero importance</strong> were never selected for any split‚Äîthey didn't provide useful discrimination power given the other available features.</p>
                            </div>
                            
                            <div class="guide-section">
                                <h5>How It's Calculated</h5>
                                <p>For decision trees, importance is computed using <strong>Mean Decrease in Impurity (MDI)</strong>:</p>
                                <ol>
                                    <li>At each split on feature X, measure how much Gini impurity (or entropy) decreased</li>
                                    <li>Weight that decrease by the number of samples reaching that node</li>
                                    <li>Sum up all the weighted decreases for feature X across the entire tree</li>
                                    <li>Normalize so all importances sum to 100%</li>
                                </ol>
                                <p class="formula-note">Formula: Importance(X) = Œ£ [n<sub>node</sub> √ó ŒîImpurity] for all nodes splitting on X</p>
                            </div>
                            
                            <div class="guide-section">
                                <h5>‚ö†Ô∏è Critical Caveats for Interpretation</h5>
                                <ul>
                                    <li><strong>Importance ‚â† Causation:</strong> A variable can be highly important because it's correlated with the true causal driver, not because it causes the outcome. "Ice cream sales" might predict drownings (both correlate with summer), but ice cream doesn't cause drownings.</li>
                                    <li><strong>Correlated features compete:</strong> If two variables carry similar information (e.g., "income" and "home value"), the tree may only use one. The unused variable gets low importance even though it's predictive.</li>
                                    <li><strong>Scale doesn't matter:</strong> Unlike some methods, tree-based importance isn't affected by whether a variable is in dollars vs. thousands of dollars.</li>
                                    <li><strong>Categorical variables with many levels</strong> can appear artificially important because they offer more potential split points.</li>
                                </ul>
                            </div>
                            
                            <div class="guide-section">
                                <h5>üéØ Marketing Applications</h5>
                                <ul>
                                    <li><strong>Campaign prioritization:</strong> Focus retention efforts on the drivers that matter most. If "Days Since Last Purchase" dominates, recency-triggered campaigns may be most effective.</li>
                                    <li><strong>Data collection guidance:</strong> High-importance variables are worth investing in better data quality and coverage.</li>
                                    <li><strong>Stakeholder communication:</strong> Use importance rankings to explain which factors the model "pays attention to"‚Äîbut always pair with business logic validation.</li>
                                    <li><strong>Feature engineering ideas:</strong> If behavioral variables dominate demographics, consider creating more engagement-based features.</li>
                                </ul>
                            </div>
                        </div>
                    </details>
                </div>

                <!-- Dynamic Interpretation -->
                <div class="interpretation-panel" id="interpretation-panel">
                    <h4>üí° Model Summary & Business Rules</h4>
                    <div id="interpretation-content">
                        <p class="placeholder-text">Build a tree to see model interpretation...</p>
                    </div>
                </div>

                <!-- Overall Model Guidance -->
                <details class="interpretation-aid model-guidance">
                    <summary>üìä How to Use Your Decision Tree Model</summary>
                    <div class="interpretation-content">
                        <div class="guide-section">
                            <h5>üéØ Turning Rules into Action</h5>
                            <p>Decision trees produce <strong>IF-THEN rules</strong> that map directly to marketing segments:</p>
                            <ul>
                                <li><strong>Email targeting:</strong> Create segments matching each leaf's conditions</li>
                                <li><strong>Offer personalization:</strong> Different offers for high-risk vs low-risk segments</li>
                                <li><strong>Budget allocation:</strong> Prioritize retention spend on high-churn-probability segments</li>
                                <li><strong>Customer journey triggers:</strong> Set up automations when customers enter certain rules</li>
                            </ul>
                        </div>
                        <div class="guide-section">
                            <h5>‚ö†Ô∏è Common Pitfalls</h5>
                            <ul>
                                <li><strong>Overfitting:</strong> If training accuracy >> test accuracy, simplify the tree (reduce depth)</li>
                                <li><strong>Leaky features:</strong> Beware variables that "know" the outcome (e.g., "cancellation_date" predicting churn)</li>
                                <li><strong>Class imbalance:</strong> With rare events (2% churn), accuracy is misleading‚Äîfocus on precision/recall</li>
                                <li><strong>Small leaves:</strong> Rules based on 5 customers aren't reliable‚Äîenforce minimum samples</li>
                            </ul>
                        </div>
                        <div class="guide-section">
                            <h5>üìà Improving Your Model</h5>
                            <ul>
                                <li><strong>Add features:</strong> Behavioral data (purchase recency, engagement) often beats demographics</li>
                                <li><strong>Feature engineering:</strong> Ratios, trends, and time-since variables can be powerful</li>
                                <li><strong>Try different depths:</strong> Plot train vs test accuracy at various depths to find the sweet spot</li>
                                <li><strong>Consider ensemble methods:</strong> Random Forests (many trees averaged) usually beat single trees</li>
                            </ul>
                        </div>
                    </div>
                </details>

                <!-- Export Buttons -->
                <div class="export-buttons">
                    <button type="button" id="export-rules-btn" class="btn-secondary" disabled>
                        üìÑ Export Tree Rules
                    </button>
                    <button type="button" id="export-predictions-btn" class="btn-secondary" disabled>
                        üìä Export Predictions CSV
                    </button>
                </div>
            </div>
        </section>
    </main>

    <footer class="app-footer">
        <div class="footer-content">
            <div class="footer-nav">
                <a href="../../../index.html" class="back-link">‚Üê Back to Tool Selection</a>
            </div>
            <div class="footer-meta">
                <span class="meta-item">Created: 2026-02-02</span>
                <span class="separator">‚Ä¢</span>
                <span class="meta-item">Last Updated: 2026-02-02</span>
            </div>
            <div class="footer-citation">
                <div class="citation-label">Cite this tool:</div>
                <div class="citation-text">Baker, A. (2026). Decision Tree Classifier. <em>Dr. Baker's Marketing Analytics Tools</em>. Retrieved from <a href="https://drbakermarketing.com/apps/decisiontrees/classifier/" target="_blank">https://drbakermarketing.com/apps/decisiontrees/classifier/</a></div>
            </div>
            <div class="footer-copyright">
                &copy; 2026 Andrew Baker. All rights reserved.
            </div>
        </div>
    </footer>

    <!-- Node Details Modal (Read-only, appears when clicking nodes in auto mode) -->
    <div id="node-details-modal" class="node-details-modal hidden">
        <div class="node-details-header">
            <h4 id="node-details-title">üìä Node Details</h4>
            <button type="button" id="close-node-details" class="close-btn">‚úï</button>
        </div>
        <div id="node-details-content" class="node-details-content">
            <!-- Populated by JS -->
        </div>
    </div>

    <!-- Scripts -->
    <script src="../../../shared/js/csv_utils.js"></script>
    <script src="../../../shared/js/auth_tracking.js"></script>
    <script src="../../../shared/js/auth_bar.js"></script>
    <script src="scenarios.js"></script>
    <script src="decision_tree.js"></script>
    <script src="tree_visualizer.js"></script>
    <script src="manual_builder.js"></script>
    <script src="main.js"></script>
    <script src="dt_tutorial.js"></script>
</body>
</html>
