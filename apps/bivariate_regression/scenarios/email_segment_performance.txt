# Title
Email Nurture Streams vs. Average Order Value

# Description
<p>
You are advising the CRM team for a fashion e-commerce brand that wants to improve <strong>average order value (AOV)</strong> from new subscribers. Every new email subscriber is automatically dropped into one of four nurture streams, each emphasizing a different type of content. The team wants to understand whether any stream is truly outperforming the others, beyond random noise.
</p>
<p>
The four streams are:
</p>
<ul>
  <li><strong>Control_Group:</strong> A light-touch stream with generic brand updates and new arrivals.</li>
  <li><strong>Discount_Focus:</strong> Weekly promotional offers, limited-time discounts, and coupon codes.</li>
  <li><strong>New_Arrivals:</strong> Curated recommendations highlighting the newest drops and limited collections.</li>
  <li><strong>Brand_Story:</strong> Longer-form content focused on sustainability, designer stories, and community impact.</li>
</ul>
<p>
The dataset captures the AOV of customers who placed at least one order after entering a stream. Differences between groups are intentionally modest and overlapping; you will not see a “magic bullet” segment. This reflects the reality that email content strategy often delivers incremental, not dramatic, lifts.
</p>
<p>
Your analytic task is to treat <strong>Email_Segment</strong> as a categorical predictor and <strong>Average_Order_Value</strong> as the outcome. You want to quantify how much more (or less) each stream performs relative to a chosen reference and whether those differences are statistically and practically meaningful.
</p>

# How to use
<ul>
  <li><strong>Choose the reference group:</strong> Start with <em>Control_Group</em> as the baseline to interpret each coefficient as an incremental AOV difference vs. the default experience.</li>
  <li><strong>Interpret the coefficients:</strong> Translate estimated differences (e.g., “+ \$3.20 for Discount_Focus”) into meaningful business language about expected lift per order.</li>
  <li><strong>Compare significance and magnitude:</strong> Use p-values and confidence intervals together to highlight which streams are both statistically reliable and practically relevant.</li>
  <li><strong>Discuss trade-offs:</strong> Use the findings to frame next steps: doubling down on high-performing streams, iterating weak ones, or experimenting with hybrid content strategies.</li>
</ul>
