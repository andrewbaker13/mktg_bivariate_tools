<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Propensity Score Matching Tool</title>
  <link rel="stylesheet" href="../../shared/css/main.css">
  <link rel="stylesheet" href="log_regression.css">
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <script src="../../shared/js/predictor_utils.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-290ZJ9RE04"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-290ZJ9RE04');
    </script>
</head><body>
  <header class="intro hero-header">
    <div class="hero-header__top">
      <h1>Propensity Score Matching</h1>
      <div class="hero-context">
        <span class="badge">Causal inference</span>
      </div>
    </div>
    <p class="hero-header__lede">
      Estimate and check propensity scores for observational marketing data, then compare treated vs. matched control outcomes. Upload raw rows, pick a treatment indicator and covariates, and the tool will fit a logistic model for treatment, perform nearest-neighbor matching, and report balance diagnostics and treatment effects.
    </p>
  </header>

  <main class="app-main">
    <section class="test-overview">
      <h2>OVERVIEW &amp; APPROACH</h2>
      <div class="card">
        <p>
          Propensity score methods use logistic regression to estimate the <strong>probability of receiving a treatment</strong> (such as being exposed to a campaign) given a set of covariates \(X_1, X_2, \dots, X_p\). By matching treated and control units with similar propensity scores, we aim to compare groups that look similar on observed covariates, mimicking some aspects of a randomized experiment.
        </p>
        <p class="equation">
          <strong>Propensity score model:</strong>
          $$ \log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \dots + \beta_p X_{pi} $$
          where \(p_i = \Pr(T_i = 1 \mid X_{1i}, \dots, X_{pi})\) is the probability of treatment for unit \(i\).
        </p>
        <p class="equation">
          <strong>Matching &amp; balance:</strong>
          units with similar \(p_i\) but different treatment status are paired (for example, 1:1 nearest-neighbor matching). Balance diagnostics then compare covariate distributions between treated and matched controls; if balance is good, the estimated treatment effect on this matched sample is more credible than a raw, unadjusted comparison.
        </p>
        <details class="additional-notes">
          <summary>Treatment indicator &amp; covariates</summary>
          <p>
            The treatment must be coded as a binary variable (for example, 0/1 or exposed/not exposed). Covariates are variables you believe may influence both treatment assignment and the outcome (for example, prior spend, engagement, or segment). Matching can only adjust for observed covariates, so thoughtful selection and clear causal reasoning are still essential.
          </p>
        </details>
      </div>
    </section>

    <section class="scenario-section">
      <h2>OBSERVATIONAL STUDY SCENARIOS</h2>
      <div class="card">
        <div class="scenario-controls">
          <label for="scenario-select">Load a matching scenario:</label>
          <div class="scenario-controls__input">
            <select id="scenario-select">
              <option value="">Manual inputs (no preset)</option>
            </select>
            <button id="scenario-download" class="secondary hidden" type="button" disabled>
              Download scenario dataset
            </button>
          </div>
        </div>
        <div id="scenario-description">
          <p>
            Use presets to explore quasi-experimental setups, such as <em>campaign exposure vs. no exposure</em> or <em>loyalty program enrollment vs. non-enrollment</em>.
            Each scenario provides a raw data file you can download, inspect in Excel, and re-upload to see how propensity matching changes the comparison.
          </p>
        </div>
      </div>
    </section>

    <section class="inputs-panel">
      <h2>INPUTS &amp; SETTINGS</h2>
      <div class="card data-entry-card">
        <div class="input-header">
          <h3>Upload Raw Data File</h3>
        </div>
        <p class="panel-intro">
          Upload a CSV file with raw case-level data. Include one binary outcome column (0/1 or two categories) and multiple predictors (numeric or categorical). Headers are required.
        </p>
        <div class="dropzone" id="raw-dropzone" role="button" tabindex="0">
          <p class="dropzone-title">Drag &amp; Drop raw data file (.csv, .tsv, .txt)</p>
          <p class="dropzone-note">Include headers; at least one binary outcome column and predictors (numeric or text for categorical).</p>
          <button type="button" id="raw-browse" class="secondary">Browse files</button>
        </div>
        <input type="file" id="raw-input" accept=".csv,.tsv,.txt" hidden>
        
        <div class="template-buttons">
          <button type="button" id="raw-template-download">Download raw template</button>
        </div>
        <p class="upload-status" id="raw-upload-status">No file uploaded.</p>
      </div>

      <div id="variable-selection-panel" class="card variable-selection-panel hidden">
        <h3>Assign Variables</h3>
        <p>Select your outcome (Y) and one or more predictors. Set predictor types and reference levels for categorical variables.</p>
        <div class="variable-selectors-grid">
          <div class="variable-column">
            <label for="outcome-select">Outcome (binary)</label>
            <select id="outcome-select"></select>
            <div id="outcome-focal-wrapper" class="muted small hidden" style="margin-top: 0.5rem;">
              <label for="outcome-focal-select">Focal outcome (treated as 1):</label>
              <select id="outcome-focal-select"></select>
            </div>
            <p id="outcome-coding-note" class="muted" style="margin-top: 0.25rem;"></p>
          </div>
          <div class="variable-column">
            <h4>Predictors</h4>
            <div id="predictor-list" class="predictor-list stacked"></div>
          </div>
        </div>
        <div id="assignment-summary" class="muted"></div>
        <p id="input-status" class="muted"></p>
        <p id="row-filter-status" class="muted"></p>
      </div>

      <div class="card confidence-card">
        <h3>Confidence Level &amp; Reporting</h3>
        <p>Set the significance level for hypothesis tests and confidence intervals.</p>
        <div class="alpha-controls">
          <label for="alpha">Significance level (&alpha;)</label>
          <input type="number" id="alpha" min="0.001" max="0.5" step="0.001" value="0.05">
          <div class="confidence-buttons" role="group" aria-label="Select confidence level">
            <button type="button" class="confidence-button conf-level-btn" data-level="0.90">90% Conf.</button>
            <button type="button" class="confidence-button conf-level-btn selected" data-level="0.95">95% Conf.</button>
            <button type="button" class="confidence-button conf-level-btn" data-level="0.99">99% Conf.</button>
          </div>
          <label class="switch-option" style="margin-top: 0.75rem;">
            <input type="checkbox" id="logreg-standardize-continuous">
            <span>Standardize continuous predictors (mean 0, SD 1)</span>
          </label>
          <p class="hint">
            Standardization affects model fitting and effect plots only. Summary statistics always report predictors on their original scale.
          </p>
        </div>
      </div>
    </section>

    <section class="visual-output" aria-labelledby="visual-output-heading">
      <h2 id="visual-output-heading">VISUAL OUTPUT</h2>
      <div class="card">
        <article class="chart-card">
          <h3>Actual vs. Fitted</h3>
          <div id="plot-actual-fitted" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="Plot of actual versus fitted outcome values."></div>
          <p id="plot-actual-fitted-caption" class="chart-note"></p>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p class="muted">
              Each point plots a fitted probability on the horizontal axis and the observed 0/1 outcome (with a small amount of vertical jitter for visibility) on the vertical axis. Points clustered near 0 or 1 on the x-axis indicate confident predictions; a mix of 0s and 1s at similar fitted probabilities indicates uncertainty. Strong patterns or obvious outliers can signal model misspecification or influential cases to review.
            </p>
          </details>
        </article>
        <article class="chart-card">
          <h3>Predicted probabilities vs. focal predictor</h3>
          <div class="effect-controls">
            <label for="effect-focal-select">Focal predictor</label>
            <select id="effect-focal-select"></select>
            <div class="range-controls">
              <span>Focal range (continuous):</span>
              <label><input type="radio" name="effect-range" value="sd" checked> Mean +/- 2 SD</label>
              <label><input type="radio" name="effect-range" value="observed"> Observed min/max</label>
              <label><input type="radio" name="effect-range" value="custom"> Custom</label>
              <div class="custom-range" id="custom-range-wrapper" style="display:none;">
                <label>Min <input type="number" id="effect-range-min" step="any"></label>
                <label>Max <input type="number" id="effect-range-max" step="any"></label>
              </div>
            </div>
            <div class="effect-constants-card">
              <h4>Hold other predictors constant</h4>
              <p class="muted">
                Choose levels/values for the non-focal predictors used when plotting the focal curve.
              </p>
              <div id="effect-nonfocal-continuous" class="effect-nonfocal-levels"></div>
              <div id="effect-nonfocal-levels" class="effect-nonfocal-levels"></div>
            </div>
            <p id="effect-constants-note" class="muted"></p>
          </div>
          <div id="plot-effect" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="Predicted probabilities versus focal predictor."></div>
          <p id="plot-effect-caption" class="chart-note"></p>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p id="effect-interpretation" class="muted">
              The line (or bars for categorical focals) shows the predicted probability that the focal outcome (coded as 1) occurs while holding other predictors constant at chosen values. Steeper slopes or larger gaps between bars imply stronger effects. Confidence bands/bars reflect the statistical uncertainty for those probabilities; wider bands mean less certainty. If bands for different settings overlap heavily, the model may not distinguish them well at those values.
            </p>
          </details>
        </article>
      </div>
    </section>

    <section class="summary-section" aria-labelledby="summary-heading">
      <h2 id="summary-heading">SUMMARY STATISTICS</h2>
      <div class="card summary-stats-card">
        <h3>Summary Statistics</h3>
        <div class="summary-stats-grid">
          <div>
            <h4>Outcome &amp; Continuous Predictors</h4>
            <table class="summary-table">
              <thead>
                <tr>
                  <th>Variable</th>
                  <th>Mean</th>
                  <th>Median</th>
                  <th>Std. Dev.</th>
                  <th>Min</th>
                  <th>Max</th>
                </tr>
              </thead>
              <tbody id="numeric-summary-body">
                <tr><td colspan="6">Provide data to see summary statistics.</td></tr>
              </tbody>
            </table>
          </div>
          <div>
            <h4>Categorical Predictors (% by level)</h4>
            <table class="summary-table">
              <thead>
                <tr>
                  <th>Predictor</th>
                  <th>Level</th>
                  <th>Percent</th>
                </tr>
              </thead>
              <tbody id="categorical-summary-body">
                <tr><td colspan="3">Provide data to see level percentages.</td></tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </section>

    <section class="test-results" aria-labelledby="test-results-heading">
      <h2 id="test-results-heading">TEST RESULTS</h2>

      <div class="card regression-equation-card">
        <h3>Regression Equation</h3>
        <p id="regression-equation-output" class="regression-equation-text">
          Provide data to see the fitted regression equation.
        </p>
        <p class="template-download">
          <button type="button" id="logreg-download-results" class="secondary">
            Download predicted probabilities (CSV)
          </button>
        </p>
        <p class="hint">
          The downloaded file includes your original raw data plus two columns: <code>p_hat</code> (the model&rsquo;s
          predicted probability of the focal outcome for each observation) and <code>neg_loglik_contribution</code>,
          the individual contribution to the negative log-likelihood penalty used to fit the model.
        </p>
      </div>

      <div class="card metrics-panel">
        <div class="metric-output"><span>Log-likelihood:</span><span id="metric-loglik" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Null deviance:</span><span id="metric-null-dev" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Residual deviance:</span><span id="metric-resid-dev" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Model chi-square:</span><span id="metric-chi2" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Model p-value:</span><span id="metric-pmodel" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Pseudo R-squared:</span><span id="metric-r2" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Sample size (n):</span><span id="metric-n" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Alpha:</span><span id="metric-alpha" class="dynamic-value">&ndash;</span></div>
        <details class="interpretation-aid">
          <summary>Interpretation Aid</summary>
          <p class="muted">
            <strong>Log-likelihood / Deviance:</strong> Log-likelihood measures how well the model explains the observed pattern of 0/1 outcomes; deviance is a scaled version that compares the fitted model to a saturated one. Lower deviance means better fit.
          </p>
          <p class="muted">
            <strong>Model chi-square &amp; p-value:</strong> Compares the fitted model to an intercept-only (null) model using the difference in deviance. A small p-value (&lt; alpha) means the predictors, as a set, improve the ability to predict success vs. failure.
          </p>
          <p class="muted">
            <strong>Pseudo R-squared:</strong> A rough analogue of R-squared that summarizes how much the model improves fit relative to the null model. It is useful as a descriptive measure but should not be overinterpreted as “percent of variance explained.”
          </p>
          <p class="muted">
            <strong>n:</strong> Sample size and available information for estimating effects. Very small n can make estimates unstable or produce separation issues where a predictor perfectly predicts the outcome.
          </p>
          <p class="muted">
            <strong>Alpha:</strong> Your chosen significance level. P-values below alpha are treated as statistically reliable; above alpha are treated as not statistically reliable.
          </p>
        </details>
      </div>

      <div class="dual-panels">
        <article class="card dual-panel">
          <h3>APA-Style Statistical Reporting</h3>
          <p id="apa-report"></p>
        </article>
        <article class="card dual-panel">
          <h3>Managerial Interpretation</h3>
          <p id="managerial-report"></p>
        </article>
      </div>

      <div class="card summary-section">
        <h3>Coefficient Estimates (Log-odds and Odds Ratios)</h3>
        <table class="summary-table">
          <thead>
            <tr>
              <th>Predictor</th>
              <th>Level / Term</th>
              <th>Estimate (log-odds)</th>
              <th>Standard Error</th>
              <th>z</th>
              <th>p-value</th>
              <th>Odds Ratio</th>
              <th>Partial &eta;<sup>2</sup></th>
              <th id="coef-ci-lower-header">Lower Bound</th>
              <th id="coef-ci-upper-header">Upper Bound</th>
            </tr>
          </thead>
          <tbody id="coef-table-body">
            <tr><td colspan="9">Provide data to see coefficient estimates.</td></tr>
          </tbody>
        </table>
        <details class="interpretation-aid">
          <summary>Interpretation Aid</summary>
          <div id="coef-interpretation" class="muted"></div>
        </details>
      </div>
    </section>

    <section class="diagnostics-section">
      <h2>DIAGNOSTICS &amp; ASSUMPTIONS</h2>
      <div class="card">
        <details class="diagnostics-details">
          <summary>Diagnostics &amp; Assumption Checks</summary>
          <div id="diagnostics-content">
            <p class="muted">Run the analysis to see checks on multicollinearity, variance patterns, and normality of residuals. Use these as prompts for plots and follow-up modeling, not as strict pass/fail gates.</p>
            <div id="diag-row-screening" class="diagnostic-block"></div>
            <div id="diag-outcome-balance" class="diagnostic-block"></div>
            <div id="diag-rare-levels" class="diagnostic-block"></div>
            <div id="diag-collinearity" class="diagnostic-block"></div>
            <div id="diag-residuals" class="diagnostic-block"></div>
            <div class="chart-card">
              <h4>Residuals vs. Fitted</h4>
              <div id="plot-residuals" class="chart-placeholder" role="img" aria-live="polite"
                aria-label="Residuals versus fitted values."></div>
              <p id="plot-residuals-caption" class="chart-note"></p>
            </div>
          </div>
        </details>
      </div>
    </section>
  </main>

    <footer class="app-footer">
    <p class="page-timestamps">Created: <span id="created-date"></span> &middot; Last updated: <span id="modified-date"></span></p>
      <p><a href="../../index.html">Back to Stat Analysis Selection</a></p>
      <p class="citation">
        Cite as: Baker, Andrew. (2025). Logistic Regression Tool. Marketing Bivariate Tools.
        https://github.com/andre/mktg_bivariate_tools/apps/log_regression/log_regression.html
      </p>
    </footer>

  <script src="../../shared/js/csv_utils.js"></script>
  <script src="../../shared/js/stats_utils.js"></script>
  <script src="../../shared/js/fan_chart_utils.js"></script>
  <script src="../../shared/js/stacked_bar_utils.js"></script>
  <script src="../../shared/js/ui_utils.js"></script>
  <script src="log_reg_app.js"></script>
  <div id="logreg-loading-overlay" class="loading-overlay" aria-hidden="true">
    <div class="loading-content">
      <p><strong>Fitting logistic regression model…</strong></p>
      <p class="muted">For larger datasets this may take a moment. Please wait.</p>
    </div>
  </div>
</body>

</html>
