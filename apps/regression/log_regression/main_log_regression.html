<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Logistic Regression Tool</title>
  <link rel="stylesheet" href="../../../shared/css/main.css">
    <script src="../../../shared/js/tracking.js"></script>
  <link rel="stylesheet" href="../../../shared/css/auth_bar.css">
  <link rel="stylesheet" href="main_log_regression.css">
  <script src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>
  <script src="../../../shared/js/predictor_utils.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-290ZJ9RE04"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-290ZJ9RE04');
    </script>
</head><body>
  <div class="auth-bar">
    <div class="auth-bar__container">
      <div></div>
      <div id="auth-bar-content" class="auth-bar__links">
        <a href="../../../admin_pages/login.html">Login</a>
        <a href="../../../admin_pages/register.html">Create Account</a>
      </div>
    </div>
  </div>
  <header class="intro hero-header">
    <div class="hero-header__top">
      <h1>Logistic Regression Tool</h1>
      <div class="hero-context">
        <span class="badge">New</span>
      </div>
    </div>
    <p class="hero-header__lede">
      Fit and interpret logistic regression models for marketing data with a binary outcome and a mix of continuous and categorical predictors. Upload raw rows, pick your success outcome, and compare the marginal effects of each predictor on conversion probabilities with confidence intervals and diagnostics.
    </p>
  </header>

  <!-- Professor Mode Banner -->
  <div class="professor-mode-banner">
    <div class="professor-mode-content">
      <div class="professor-mode-info">
        <h3>üë®‚Äçüè´ Professor Mode: Guided Learning Experience</h3>
        <p>New to logistic regression? Enable Professor Mode for step-by-step guidance through building and interpreting your first model!</p>
      </div>
      <label class="professor-mode-toggle">
        <input type="checkbox" id="professorMode">
        <span>Enable Professor Mode</span>
      </label>
    </div>
  </div>

  <main class="app-main">
    <section class="test-overview">
      <h2>TEST OVERVIEW &amp; EQUATIONS</h2>
      <div class="card">
        <p>
          Logistic regression estimates how the <strong>probability</strong> of a binary outcome (such as convert vs. not convert) changes with several predictors \(X_1, X_2, \dots, X_p\). Each coefficient shows the unique association of a predictor with the log-odds of success, holding the others constant.
        </p>
        <p class="equation">
          <strong>Model:</strong>
          $$ \log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \dots + \beta_p X_{pi} $$
          where \(p_i = \Pr(Y_i = 1 \mid X_{1i}, \dots, X_{pi})\).
        </p>
        <p class="equation">
          <strong>Coefficient tests:</strong>
          $$ z_j = \frac{\hat{\beta}_j}{\mathrm{SE}(\hat{\beta}_j)} $$
          with p-values based on the standard normal distribution.
        </p>
        <p class="equation">
          <strong>Model comparison:</strong>
          $$ \Delta D = D_{\text{null}} - D_{\text{model}} $$
          can be compared using a chi-square test to see whether the predictors, as a set, improve fit vs. an intercept-only model.
        </p>
        <details class="additional-notes">
          <summary>Binary Outcome &amp; Predictor Types</summary>
          <p>
            The outcome must be coded as a binary variable (for example, 0/1 or success/failure). Continuous predictors use their numeric scale. Categorical predictors are dummy-coded with a reference level, so each coefficient compares a category to its reference while holding other predictors constant.
          </p>
        </details>
      </div>
    </section>

    <section class="scenario-section">
      <h2>MARKETING SCENARIOS</h2>
      <div class="card">
        <div class="scenario-controls">
          <label for="scenario-select">Load a marketing scenario:</label>
          <div class="scenario-controls__input">
            <select id="scenario-select">
              <option value="">Manual inputs (no preset)</option>
            </select>
            <button id="scenario-download" class="secondary hidden" type="button" disabled>
              Download scenario dataset
            </button>
          </div>
        </div>
        <div id="scenario-description">
          <p>
            Use presets to explore realistic use cases, such as <em>ad spend vs. revenue</em> or <em>control vs. treatment on order value</em>.
            Each scenario can expose either a summary CSV of aggregated statistics or a raw data file that you can download, edit in Excel, and re-upload.
          </p>
        </div>
      </div>
    </section>

    <section class="inputs-panel">
      <h2>INPUTS &amp; SETTINGS</h2>
      <div class="card data-entry-card">
        <div class="input-header">
          <h3>Upload Raw Data File</h3>
        </div>
        <p class="panel-intro">
          Upload a CSV file with raw case-level data. Include one binary outcome column (0/1 or two categories) and multiple predictors (numeric or categorical). Headers are required.
        </p>
        <div class="dropzone" id="raw-dropzone" role="button" tabindex="0">
          <p class="dropzone-title">Drag &amp; Drop raw data file (.csv, .tsv, .txt)</p>
          <p class="dropzone-note">Include headers; at least one binary outcome column and predictors (numeric or text for categorical).</p>
          <button type="button" id="raw-browse" class="secondary">Browse files</button>
        </div>
        <input type="file" id="raw-input" accept=".csv,.tsv,.txt" hidden>
        
        <div class="template-buttons">
          <button type="button" id="raw-template-download">Download raw template</button>
        </div>
        <p class="upload-status" id="raw-upload-status">No file uploaded.</p>
      </div>

      <div id="variable-selection-panel" class="card variable-selection-panel hidden">
        <h3>Assign Variables</h3>
        <p>Select your outcome (Y) and one or more predictors. Set predictor types and reference levels for categorical variables.</p>
        <div class="variable-selectors-grid">
          <div class="variable-column">
            <label for="outcome-select">Outcome (binary)</label>
            <select id="outcome-select"></select>
            <div id="outcome-focal-wrapper" class="muted small hidden" style="margin-top: 0.5rem;">
              <label for="outcome-focal-select">Focal outcome (treated as 1):</label>
              <select id="outcome-focal-select"></select>
            </div>
            <p id="outcome-coding-note" class="muted" style="margin-top: 0.25rem;"></p>
          </div>
          <div class="variable-column">
            <h4>Predictors</h4>
            <div id="predictor-list" class="predictor-list stacked"></div>
          </div>
        </div>
        <div id="assignment-summary" class="muted"></div>
        <p id="input-status" class="muted"></p>
        <p id="row-filter-status" class="muted"></p>
      </div>

      <div class="card confidence-card">
        <h3>Confidence Level &amp; Reporting</h3>
        <p>Set the significance level for hypothesis tests and confidence intervals.</p>
        <div class="alpha-controls">
          <label for="alpha">Significance level (&alpha;)</label>
          <input type="number" id="alpha" min="0.001" max="0.5" step="0.001" value="0.05">
          <div class="confidence-buttons" role="group" aria-label="Select confidence level">
            <button type="button" class="confidence-button conf-level-btn" data-level="0.90">90% Conf.</button>
            <button type="button" class="confidence-button conf-level-btn selected" data-level="0.95">95% Conf.</button>
            <button type="button" class="confidence-button conf-level-btn" data-level="0.99">99% Conf.</button>
          </div>
          <label class="switch-option" style="margin-top: 0.75rem;">
            <input type="checkbox" id="logreg-standardize-continuous">
            <span>Standardize continuous predictors (mean 0, SD 1)</span>
          </label>
          <p class="hint">
            Standardization affects model fitting and effect plots only. Summary statistics always report predictors on their original scale.
          </p>
        </div>
      </div>
    </section>

    <section class="visual-output" aria-labelledby="visual-output-heading">
      <h2 id="visual-output-heading">VISUAL OUTPUT</h2>
      <div class="card">
        <article class="chart-card">
          <h3>Confusion Matrix</h3>
          <details class="confusion-advanced-options">
            <summary>Advanced Options</summary>
            <div class="confusion-controls">
              <label for="confusion-threshold">Classification threshold:</label>
              <input type="number" id="confusion-threshold" min="0" max="1" step="0.05" value="0.5">
              <span class="hint">(Pr ‚â• threshold ‚Üí predict 1)</span>
            </div>
          </details>
          <div id="plot-confusion-matrix" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="Confusion matrix showing classification performance."></div>
          <p id="plot-confusion-caption" class="chart-note"></p>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p class="muted">
              The confusion matrix shows how well the model classifies observations into the two outcome categories. The rows represent the actual outcomes (0 or 1) and columns represent the predicted outcomes. Diagonal cells (true positives and true negatives) indicate correct predictions; off-diagonal cells show errors. Adjust the classification threshold to balance sensitivity (correctly identifying 1s) versus specificity (correctly identifying 0s) based on your business priorities.
            </p>
            <p class="muted">
              <strong>Classification Metrics:</strong> <strong>Accuracy</strong> = overall % correct. <strong>Sensitivity (Recall)</strong> = % of actual 1s correctly identified. <strong>Specificity</strong> = % of actual 0s correctly identified. <strong>Precision (PPV)</strong> = % of predicted 1s that are actually 1. <strong>F1 Score</strong> = harmonic mean of precision and recall (balances both). <strong>NPV</strong> = % of predicted 0s that are actually 0.
            </p>
          </details>
          <div class="metrics-panel" style="margin-top: 1rem;">
            <h4>Classification Performance (at threshold = <span id="cm-threshold-display">0.5</span>)</h4>
            <div class="metric-output"><span>Accuracy:</span><span id="metric-accuracy" class="dynamic-value">&ndash;</span></div>
            <div class="metric-output"><span>Sensitivity (Recall):</span><span id="metric-sensitivity" class="dynamic-value">&ndash;</span></div>
            <div class="metric-output"><span>Specificity:</span><span id="metric-specificity" class="dynamic-value">&ndash;</span></div>
            <div class="metric-output"><span>Precision (PPV):</span><span id="metric-precision" class="dynamic-value">&ndash;</span></div>
            <div class="metric-output"><span>F1 Score:</span><span id="metric-f1" class="dynamic-value">&ndash;</span></div>
            <div class="metric-output"><span>Negative Predictive Value:</span><span id="metric-npv" class="dynamic-value">&ndash;</span></div>
          </div>
        </article>
        <article class="chart-card">
          <h3>ROC Curve</h3>
          <div id="plot-roc" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="ROC curve showing model discrimination."></div>
          <p id="plot-roc-caption" class="chart-note"></p>
          <div class="metric-output" style="margin-top: 0.5rem;"><span>AUC (Area Under Curve):</span><span id="metric-auc" class="dynamic-value">&ndash;</span></div>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p class="muted">
              The ROC curve plots the True Positive Rate (sensitivity) against the False Positive Rate (1 - specificity) across all possible classification thresholds. A curve closer to the top-left corner indicates better discrimination. The Area Under Curve (AUC) summarizes overall performance: 1.0 = perfect discrimination, 0.5 = no better than random guessing, < 0.5 = worse than random. AUC > 0.7 is often considered acceptable, > 0.8 good, > 0.9 excellent.
            </p>
            <p class="muted">
              <strong>Reading the curve:</strong> Each point on the curve represents a different classification threshold. <strong>Hover over any point to see which threshold it represents</strong> (along with its TPR and FPR). Key thresholds (0.3, 0.5, 0.7) are marked with red dots and labeled. Moving right along the curve means lowering the threshold (classifying more cases as positive), which increases both true positives (good) and false positives (bad). The caption shows specific threshold examples for easy reference.
            </p>
          </details>
        </article>
        <article class="chart-card">
          <h3>Predicted Probability Distribution</h3>
          <div id="plot-prob-distribution" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="Histogram of predicted probabilities by actual outcome."></div>
          <p id="plot-prob-caption" class="chart-note"></p>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p class="muted">
              These overlapping histograms show the distribution of predicted probabilities for cases where the outcome was actually 0 (blue) versus actually 1 (red). Good model discrimination means the distributions are well-separated‚Äîcases with outcome = 1 should cluster at higher predicted probabilities. Heavy overlap suggests the model has difficulty distinguishing the two groups. This complements the confusion matrix by showing the full probability spectrum before thresholding.
            </p>
          </details>
        </article>
        <article class="chart-card">
          <h3>Predicted probabilities vs. focal predictor</h3>
          <div class="effect-controls">
            <label for="effect-focal-select">Focal predictor</label>
            <select id="effect-focal-select"></select>
            <div class="range-controls">
              <span>Focal range (continuous):</span>
              <label><input type="radio" name="effect-range" value="sd" checked> Mean +/- 2 SD</label>
              <label><input type="radio" name="effect-range" value="observed"> Observed min/max</label>
              <label><input type="radio" name="effect-range" value="custom"> Custom</label>
              <div class="custom-range" id="custom-range-wrapper" style="display:none;">
                <label>Min <input type="number" id="effect-range-min" step="any"></label>
                <label>Max <input type="number" id="effect-range-max" step="any"></label>
              </div>
            </div>
            <div class="effect-constants-card">
              <h4>Hold other predictors constant</h4>
              <p class="muted">
                Choose levels/values for the non-focal predictors used when plotting the focal curve.
              </p>
              <div id="effect-nonfocal-continuous" class="effect-nonfocal-levels"></div>
              <div id="effect-nonfocal-levels" class="effect-nonfocal-levels"></div>
            </div>
            <p id="effect-constants-note" class="muted"></p>
          </div>
          <div id="plot-effect" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="Predicted probabilities versus focal predictor."></div>
          <p id="plot-effect-caption" class="chart-note"></p>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p id="effect-interpretation" class="muted">
              The line (or bars for categorical focals) shows the predicted probability that the focal outcome (coded as 1) occurs while holding other predictors constant at chosen values. Steeper slopes or larger gaps between bars imply stronger effects. Confidence bands/bars reflect the statistical uncertainty for those probabilities; wider bands mean less certainty. If bands for different settings overlap heavily, the model may not distinguish them well at those values.
            </p>
          </details>
        </article>
        <article class="chart-card">
          <h3>Variable Importance (Odds Ratios)</h3>
          <div id="plot-variable-importance" class="chart-placeholder" role="img" aria-live="polite"
            aria-label="Forest plot of odds ratios with confidence intervals."></div>
          <p id="plot-importance-caption" class="chart-note"></p>
          <details class="interpretation-aid">
            <summary>Interpretation Aid</summary>
            <p class="muted">
              This forest plot displays odds ratios (OR) with 95% confidence intervals for each predictor. <strong>Odds ratios show multiplicative effects:</strong> OR > 1 means the predictor increases odds of the focal outcome, OR < 1 decreases odds, OR = 1 (dashed reference line) means no effect. For example, OR = 2.0 means doubling the odds (100% increase), OR = 0.5 means halving the odds (50% decrease), OR = 1.5 means 50% increase.
            </p>
            <p class="muted">
              <strong>The horizontal bars are 95% confidence intervals</strong> showing statistical uncertainty. If a bar crosses the 1.0 line, the effect is not statistically significant (could be no effect). Longer bars = more uncertainty. Variables are sorted by distance from 1.0 to show strongest effects first. The x-axis is log-scaled so equal distances represent equal multiplicative effects.
            </p>
          </details>
        </article>
      </div>
    </section>

    <section class="summary-section" aria-labelledby="summary-heading">
      <h2 id="summary-heading">SUMMARY STATISTICS</h2>
      <div class="card summary-stats-card">
        <h3>Summary Statistics</h3>
        <div class="summary-stats-grid">
          <div>
            <h4>Outcome Variable</h4>
            <table class="summary-table">
              <thead>
                <tr>
                  <th>Variable</th>
                  <th>% Focal Outcome</th>
                  <th>Count Focal</th>
                  <th>Count Non-Focal</th>
                  <th>Total n</th>
                </tr>
              </thead>
              <tbody id="outcome-summary-body">
                <tr><td colspan="5">Provide data to see outcome summary.</td></tr>
              </tbody>
            </table>
          </div>
        </div>
        <div class="summary-stats-grid">
          <div>
            <h4>Continuous Predictors</h4>
            <table class="summary-table">
              <thead>
                <tr>
                  <th>Variable</th>
                  <th>Mean</th>
                  <th>Median</th>
                  <th>Std. Dev.</th>
                  <th>Min</th>
                  <th>Max</th>
                </tr>
              </thead>
              <tbody id="numeric-summary-body">
                <tr><td colspan="6">Provide data to see summary statistics.</td></tr>
              </tbody>
            </table>
          </div>
          <div>
            <h4>Categorical Predictors (% by level)</h4>
            <table class="summary-table">
              <thead>
                <tr>
                  <th>Predictor</th>
                  <th>Level</th>
                  <th>Percent</th>
                </tr>
              </thead>
              <tbody id="categorical-summary-body">
                <tr><td colspan="3">Provide data to see level percentages.</td></tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </section>

    <section class="test-results" aria-labelledby="test-results-heading">
      <h2 id="test-results-heading">TEST RESULTS</h2>

      <div class="card regression-equation-card">
        <h3>Regression Equation</h3>
        <p id="regression-equation-output" class="regression-equation-text">
          Provide data to see the fitted regression equation.
        </p>
        <p class="template-download">
          <button type="button" id="logreg-download-results" class="secondary">
            Download predicted probabilities (CSV)
          </button>
        </p>
        <p class="hint">
          The downloaded file includes your original raw data plus two columns: <code>p_hat</code> (the model&rsquo;s
          predicted probability of the focal outcome for each observation) and <code>neg_loglik_contribution</code>,
          the individual contribution to the negative log-likelihood penalty used to fit the model.
        </p>
      </div>

      <div id="separation-warning" class="card" style="display:none; border-left: 4px solid #f59e0b; background-color: #fffbeb;">
        <h3 style="color: #d97706;">‚ö†Ô∏è Separation Detected</h3>
        <p id="separation-message" class="muted"></p>
      </div>

      <div id="model-metrics-panel" class="card metrics-panel">
        <div class="metric-output"><span>Log-likelihood:</span><span id="metric-loglik" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Null deviance:</span><span id="metric-null-dev" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Residual deviance:</span><span id="metric-resid-dev" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Model chi-square:</span><span id="metric-chi2" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Model p-value:</span><span id="metric-pmodel" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Pseudo R-squared:</span><span id="metric-r2" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Sample size (n):</span><span id="metric-n" class="dynamic-value">&ndash;</span></div>
        <div class="metric-output"><span>Alpha:</span><span id="metric-alpha" class="dynamic-value">&ndash;</span></div>
        <div id="sample-size-warning" style="display:none; margin-top: 1rem; padding: 0.75rem; background-color: #fef3c7; border-left: 3px solid #f59e0b; border-radius: 0.25rem;">
          <p class="muted" style="margin: 0; color: #92400e;"><strong>‚ö†Ô∏è Sample Size Advisory:</strong> <span id="sample-size-message"></span></p>
        </div>
        <details class="interpretation-aid">
          <summary>Interpretation Aid</summary>
          <p class="muted">
            <strong>Log-likelihood / Deviance:</strong> Log-likelihood measures how well the model explains the observed pattern of 0/1 outcomes; deviance is a scaled version that compares the fitted model to a saturated one. Lower deviance means better fit.
          </p>
          <p class="muted">
            <strong>Model chi-square &amp; p-value:</strong> Compares the fitted model to an intercept-only (null) model using the difference in deviance. A small p-value (&lt; alpha) means the predictors, as a set, improve the ability to predict success vs. failure.
          </p>
          <p class="muted">
            <strong>Pseudo R-squared:</strong> A rough analogue of R-squared that summarizes how much the model improves fit relative to the null model. It is useful as a descriptive measure but should not be overinterpreted as "percent of variance explained."
          </p>
          <p class="muted">
            <strong>n:</strong> Sample size and available information for estimating effects. Very small n can make estimates unstable or produce separation issues where a predictor perfectly predicts the outcome.
          </p>
          <p class="muted">
            <strong>Alpha:</strong> Your chosen significance level. P-values below alpha are treated as statistically reliable; above alpha are treated as not statistically reliable.
          </p>
        </details>
      </div>

      <div class="narrative-columns">
        <article class="card narrative-card">
          <h3>Managerial Interpretation</h3>
          <p id="managerial-report"></p>
        </article>
        <article class="card narrative-card">
          <h3>APA-Style Report</h3>
          <p id="apa-report"></p>
        </article>
      </div>

      <div id="coefficient-estimates-card" class="card summary-section">
        <h3>Coefficient Estimates (Log-odds and Odds Ratios)</h3>
        <table class="summary-table">
          <thead>
            <tr>
              <th>Predictor</th>
              <th>Level / Term</th>
              <th>Estimate (log-odds)</th>
              <th>Standard Error</th>
              <th>z</th>
              <th>p-value</th>
              <th>Odds Ratio</th>
              <th id="coef-ci-lower-header">Lower Bound</th>
              <th id="coef-ci-upper-header">Upper Bound</th>
            </tr>
          </thead>
          <tbody id="coef-table-body">
            <tr><td colspan="9">Provide data to see coefficient estimates.</td></tr>
          </tbody>
        </table>
        <details class="interpretation-aid">
          <summary>Interpretation Aid</summary>
          <div id="coef-interpretation" class="muted"></div>
        </details>
      </div>
    </section>

    <section class="diagnostics-section">
      <h2>DIAGNOSTICS &amp; ASSUMPTIONS</h2>
      <div class="card">
        <details class="diagnostics-details">
          <summary>Diagnostics &amp; Assumption Checks</summary>
          <div id="diagnostics-content">
            <p class="muted">Run the analysis to see checks on multicollinearity, variance patterns, and normality of residuals. Use these as prompts for plots and follow-up modeling, not as strict pass/fail gates.</p>
            <div id="diag-row-screening" class="diagnostic-block"></div>
            <div id="diag-outcome-balance" class="diagnostic-block"></div>
            <div id="diag-rare-levels" class="diagnostic-block"></div>
            <div id="diag-collinearity" class="diagnostic-block"></div>
            <div id="diag-residuals" class="diagnostic-block"></div>
            <div id="diag-hosmer-lemeshow" class="diagnostic-block">
              <h4>Hosmer-Lemeshow Goodness-of-Fit Test</h4>
              <p class="muted"><span id="hl-test-result">Run the analysis to see calibration test.</span></p>
              <details class="interpretation-aid" style="margin-top: 0.5rem;">
                <summary>What does this test?</summary>
                <p class="muted">
                  The Hosmer-Lemeshow test checks if predicted probabilities are well-calibrated‚Äîi.e., do cases with predicted probability ‚âà 70% actually have the outcome 70% of the time? The test groups observations by predicted probability and compares observed vs. expected frequencies. A <strong>large p-value (> 0.05)</strong> suggests good calibration (no evidence of poor fit). A <strong>small p-value (< 0.05)</strong> suggests the model's probability estimates may be systematically biased, even if classification accuracy is high.
                </p>
              </details>
            </div>
            <div class="chart-card">
              <h4>Actual vs. Fitted</h4>
              <div id="plot-actual-fitted" class="chart-placeholder" role="img" aria-live="polite"
                aria-label="Plot of actual versus fitted outcome values."></div>
              <p id="plot-actual-fitted-caption" class="chart-note"></p>
              <details class="interpretation-aid">
                <summary>Interpretation Aid</summary>
                <p class="muted">
                  Each point plots a fitted probability on the horizontal axis and the observed 0/1 outcome (with a small amount of vertical jitter for visibility) on the vertical axis. Points clustered near 0 or 1 on the x-axis indicate confident predictions; a mix of 0s and 1s at similar fitted probabilities indicates uncertainty. Strong patterns or obvious outliers can signal model misspecification or influential cases to review.
                </p>
              </details>
            </div>
            <div class="chart-card">
              <h4>Residuals vs. Fitted</h4>
              <div id="plot-residuals" class="chart-placeholder" role="img" aria-live="polite"
                aria-label="Residuals versus fitted values."></div>
              <p id="plot-residuals-caption" class="chart-note"></p>
            </div>
          </div>
        </details>
      </div>
    </section>
  </main>

    <footer class="app-footer">
    <div class="footer-content">
        <div class="footer-nav">
            <a href="../../../index.html">‚Üê Back to Tool Selection</a>
        </div>
        <div class="footer-meta">
            <span>Created: <span id="created-date">2025-11-15</span></span>
            <span class="meta-separator">&bull;</span>
            <span>Last Updated: <span id="modified-date">2025-12-11</span></span>
        </div>
        <div class="footer-citation">
            <span class="citation-label">Cite this tool</span>
            <p class="citation-text">
                Baker, A. (2025). <em>Logistic Regression Tool</em>. Marketing Analysis Tools.
                <br>
                <span style="font-size: 0.85em; color: #6b7280;">Retrieved from: https://drbakermarketing.com/apps/regression/log_regression/main_log_regression.html</span>
            </p>
        </div>
        <div class="footer-copyright">
            &copy; 2025 Andrew Baker. All rights reserved.
        </div>
    </div>
    </footer>

  <script src="../../../shared/js/csv_utils.js"></script>
  <script src="../../../shared/js/stats_utils.js"></script>
  <script src="../../../shared/js/fan_chart_utils.js"></script>
  <script src="../../../shared/js/stacked_bar_utils.js"></script>
  <script src="../../../shared/js/ui_utils.js"></script>
  <script src="../../../shared/js/auth_tracking.js"></script>
  <script src="../../../shared/js/auth_bar.js"></script>
  <script src="../../../shared/js/quiz_utils.js"></script>
  <script src="main_log_regression.js"></script>
  <script src="logreg_tutorial.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      initQuizButton('log_regression');
    });
  </script>
  <div id="logreg-loading-overlay" class="loading-overlay" aria-hidden="true">
    <div class="loading-content">
      <p><strong>Fitting logistic regression model‚Ä¶</strong></p>
      <p class="muted">For larger datasets this may take a moment. Please wait.</p>
    </div>
  </div>
</body>

</html>
