<h3>Single Continuous Predictor (Ideal Convergence)</h3>

<p>
This scenario is intentionally simple so you can see how the multinomial model behaves under “ideal” conditions.
There is a three-level outcome and a single continuous predictor:
</p>
<ul>
  <li><code>id</code>: row identifier.</li>
  <li><code>segment</code>: multinomial outcome with three levels (<strong>Low</strong>, <strong>Medium</strong>, <strong>High</strong>).</li>
  <li><code>score</code>: a continuous predictor (roughly standard normal) that strongly separates the three segments.</li>
</ul>

<p>
On the log-odds scale, Medium and High segments are generated as clean, nearly linear functions of <code>score</code>,
with Low as the baseline. This means:
</p>
<ul>
  <li>As <code>score</code> increases, the probability of <strong>High</strong> rises sharply.</li>
  <li><strong>Medium</strong> has a more moderate slope in score.</li>
  <li><strong>Low</strong> is most common at low values of <code>score</code>.</li>
</ul>

<p>
Because there is only one well-behaved continuous predictor and no sparse categorical levels, convergence should be
very reliable. You can use this case to:
</p>
<ul>
  <li>Verify that the model converges quickly under ideal conditions.</li>
  <li>Experiment with different step sizes, momentum, and max-iteration settings.</li>
  <li>See how the effect plot traces the clean underlying relationship between <code>score</code> and each segment’s probability.</li>
</ul>

